from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline
import random

model_name = "google/flan-t5-large"

context = """
В этот раз я хочу рассказать о том, как создал ClipGen — утилиту, которая превращает обычный буфер обмена в мощный инструмент для работы с текстом и изображениями. Весь код программы я выложил как open-source, чтобы каждый мог доработать его под свои нужды, сделав ещё удобнее и функциональнее. Ссылку на репозиторий я дам в конце статьи.

Идея: зачем мне это вообще понадобилось
Исправлять опечатки вручную долго — особенно в длинных сообщениях. А вот если надо перевести пару строк или разобраться с картинкой — тут уже приходится прыгать по вкладкам и приложениям: копируешь, идешь в DeepL, вставляешь, ждёшь, копируешь обратно. Или пытаешься понять, что за мем на немецком кинули тебе в чат.

Так возникла идея фоновой утилиты с горячими клавишами для мгновенной обработки выделенного текста — без лишних действий и переключений между окнами. Так родился ClipGen.

Что умеет ClipGen?
ClipGen — это десктопная утилита на Python, которая работает с буфером обмена и использует Google Gemini API для обработки текста и изображений. Вот что она может:


Всё это работает через горячие клавиши, без необходимости открывать отдельное окно. Выделил текст → нажал комбинацию → готово. Работает в любой программе, где есть текстовый ввод (будь то Word, Telegram или браузер). Если вставить текст нельзя, результат отобразится в интерфейсе ClipGen. Короткие тексты обрабатываются за 0.5 секунды, длинные — за секунды.

А что происходит "под капотом" при каждом нажатии? Алгоритм работы прост и эффективен: когда вы нажимаете горячую клавишу (например, Ctrl+F3 для перевода или Ctrl+F10 для анализа изображения), ClipGen автоматически эмулирует Ctrl+C для копирования выделенного контента в буфер обмена. Затем программа считывает содержимое буфера и использует конкретный промпт, привязанный к этой комбинации клавиш. Для Ctrl+F3 это будет промпт для перевода, для Ctrl+F10 — промпт для анализа изображений и так далее. Выбранный промпт вместе с вашим контентом отправляется в API Gemini, где нейросеть обрабатывает запрос и возвращает результат. После получения ответа ClipGen помещает его в буфер обмена и эмулирует Ctrl+V для вставки. Весь этот процесс происходит асинхронно в отдельном потоке, поэтому основной интерфейс не зависает и вы можете продолжать работу.

Программа полностью настраиваемая — вы можете изменить горячие клавиши под свои привычки, отредактировать промпты для каждой функции или даже переименовать кнопки в интерфейсе. Всё это легко делается через файлы конфигурации, что позволяет адаптировать ClipGen под любые ваши задачи и предпочтения.

Исправление текста (Ctrl+F1): исправляет грамматику, пунктуацию, орфографию, приводит текст в порядок с правильными тире и кавычками «ёлочками».

Переписывание (Ctrl+F2): улучшает читаемость текста, исправляет косяки голосового ввода и даже заменяет мат на цензурные, но эмоциональные выражения.

Перевод (Ctrl+F3): переводит текст между 140+ языками — с русского на английский или наоборот, если текст уже на русском.

Объяснение (Ctrl+F6): объясняет сложные термины или концепции простыми словами с примерами.

Ответы на вопросы (Ctrl+F7): отвечает на вопросы из буфера обмена.

Кастомные запросы (Ctrl+F8): выполняет любую задачу, так же из буфера.

Саркастические комментарии (Ctrl+F9): генерирует остроумные комментарии (экспериментальная функция).

Анализ изображений (Ctrl+F10): извлекает текст из картинок, переводит его (если нужно) и объясняет, что изображено.

Как это работает: немного про внутренности
ClipGen написан на Python, и вот основные компоненты:

Google Gemini API: я использую модель gemini-2.0-flash-exp. Она быстрая, точная и поддерживает работу с текстом и изображениями. Бесплатный лимит — 1000 запросов в день, а если нужно больше, можно подключить второй ключ или другую модель.

Горячие клавиши: библиотека pynput слушает нажатия клавиш, а pywin32 эмулирует копирование и вставку (пока только для Windows).

Интерфейс: customtkinter отвечает за минималистичное окно с логами и кнопками. Изначально я не хотел делать интерфейс, но оказалось, что он совсем не лишний — с ним гораздо удобнее, чем с голой консолью.

Многопоточность: ThreadPoolExecutor и multiprocessing.Queue обеспечивают асинхронную обработку запросов, чтобы ничего не зависало.

Когда вы нажимаете горячую клавишу, ClipGen копирует выделенный текст (или берёт картинку из буфера), отправляет его в Gemini с нужным промптом, получает ответ и вставляет результат обратно.

Вот пример промпта для исправления текста (из config_ru.json):
"""

question = "Что делает команда 'Ctrl+F7'?"

# Использование pipeline для генерации текста
generator = pipeline('text2text-generation', model=model_name, tokenizer=model_name)

# Формируем промпт для правильного ответа
correct_prompt = f"""
Контекст: {context}
Вопрос: {question}
Дай точный ответ на основе контекста.
"""

# Генерируем правильный ответ
correct_response = generator(correct_prompt, max_length=100, num_return_sequences=1)[0]['generated_text']

# Формируем промпт для неправильных ответов
wrong_prompt = f"""
Вопрос: {question}
Сгенерируй правдоподобный, но неверный ответ, который НЕ соответствует следующему контексту: {context}
"""

# Генерируем три неправильных ответа
wrong_responses = []
for _ in range(3):
    response = generator(wrong_prompt, max_length=100, num_return_sequences=1)[0]['generated_text']
    wrong_responses.append(response)

# Перемешиваем все ответы
all_answers = wrong_responses + [correct_response]
random.shuffle(all_answers)

# Находим индекс правильного ответа
correct_index = all_answers.index(correct_response)

# Выводим варианты ответов
print("\nВарианты ответов:")
for i, answer in enumerate(all_answers, 1):
    print(f"{i}. {answer}")
print(f"\nПравильный ответ: {correct_index + 1}")

# Загрузка модели и токенизатора для дополнительных задач
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
